---
title: "580Project"
author: "Zian Shang, Tasfia Shaikh, Thomas Huang, Nicole Dona, Matthew Davison"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r}
# include packages
library(fastDummies)
library(caret)
library(ggplot2)
library(ggrepel)
```


```{r}
# read train.data
train.data <- read.csv("train.csv", 
                       header = T, 
                       na.strings = " ?")

# remove NA
train.data <- na.omit(train.data)

# remove empty space in front of each char cell
# factorize char columns

# ***if needed, encoding char cells instead of factorizing them***

train.data[] <- lapply(train.data, 
                       function(x) {
                         if(is.character(x)) 
                           as.factor(trimws(x))
                         else x
                       })

# View(train.data)
# str(train.data)
```


```{r}
# read test data
test.data <-read.csv("test.csv", 
                     header = T, 
                     na.strings = " ?")

# remove NA
test.data <- na.omit(test.data)

# remove empty space in front of each char cell
# ***if needed, factorize/encode char cells***
test.data[] <- lapply(test.data, 
                       function(x) {
                         if(is.character(x)) 
                           as.factor(trimws(x))
                         else x
                       })


# View(test.data) 
# str(test.data)
```


### variable selection, identify important features

outliers -> Matthew
```{r}

```

correlation analysis-> Tasfia
```{r}

```


Variance Thresholding -> Zian
```{r}
# get all numeric features
numeric.data <- train.data[, sapply(train.data, is.numeric)]

# look for numbers of columns with variance near 0
nzv <- nearZeroVar(numeric.data)

# display low variance columns
# head(numeric.data[, nzv]) 

### NOTE: ### 'capital.gain'& 'capital.loss' are mostly 0's but have some very large values.
# They are classic long-tailed features, KEEP them for now.
```


###
tree-based models (CART, RF, XGBoost)
```{r}
# -> use education(categorical, factorized)
# -> no scaling
# -> no dummy encoding

### NOTE: ### Tree-based models can natively handle categorical variables (factors).
# So keep 'education' factor var, remove 'education.num'.
# No scaling or dummy encoding is needed for these models.

train.data.1 <- subset(train.data, select = -c(education.num))
test.data.1 <- subset(test.data, select = -c(education.num))

# identical(names(train.data.1), names(test.data.1))        # true
```

###
Linear/Logistic/NN/KNN 
```{r}
# -> use education.num(numeric, original)
# -> scaling
# -> dummy encode all categorical variables


### preprocess train.data
train.data.2 <- subset(train.data, select = -c(education))

# obtain numeric & categorical column names
num_cols <- names(train.data.2)[sapply(train.data.2, is.numeric)]
num_cols <- num_cols[num_cols != "education.num"]
### education.num is treated as an ordinal categorical variable (1–16), so we do not scale it.

cat_cols <- names(train.data.2)[sapply(train.data.2, is.factor)]
cat_cols <- setdiff(cat_cols, "income")  # exclude target

# scale numeric data
scaled_data <- scale(train.data.2[, num_cols])
train.data.2[, num_cols] <- scaled_data

# obtain means & stds for KNN
means <- attr(scaled_data, "scaled:center")
sds   <- attr(scaled_data, "scaled:scale")

# dummy encode all categorical variables
### note: it is normal that there are more columns being created ###

train.data.2 <- dummy_cols(
  train.data.2,
  select_columns = cat_cols,
  remove_first_dummy = TRUE,
  remove_selected_columns = TRUE
)

# -------------------------------------------------------------------------------

### preprocess test.data in the same way
test.data.2 <- subset(test.data, select = -c(education))

# num_cols are the same

# scale test data using means & stds from the train data
test.data.2[, num_cols] <- sweep(test.data.2[, num_cols], 2, means, "-")
test.data.2[, num_cols] <- sweep(test.data.2[, num_cols], 2, sds, "/")

# dummy encode all categorical variables
test.data.2 <- dummy_cols(
  test.data.2,
  select_columns = cat_cols,
  remove_first_dummy = TRUE,
  remove_selected_columns = TRUE
)

# check missing columns 
# setdiff(names(train.data.2), names(test.data.2))

### NOTE: ### level "Holand-Netherlands" appeared in the training set but 
# not in the test set, so dummy encoding did not create this column in the test data.
# We manually add the missing dummy variable and set it to 0 for all rows.
test.data.2[["native.country_Holand-Netherlands"]] <- 0


### NOTE: ### check if column names of train and test datasets are identical.
# model prediction requires the exact same column order, so align test.data 
# columns to match train.data.

# identical(names(train.data.2), names(test.data.2))      # false
test.data.2 <- test.data.2[, names(train.data.2)]

# -------------------------------------------------------------------------------

# testing: variance thresholding for preprocessed train.data.2

# get all numeric features
numeric.data <- train.data.2[, sapply(train.data.2, is.numeric)]

# look for numbers of columns with variance near 0
nzv <- nearZeroVar(numeric.data)

# obtain low variance columns, except for "capital.loss"
low.var.cols <- names(numeric.data[, nzv])
low.var.cols <- setdiff(low.var.cols, "capital.loss")
# low.var.cols

# remove them from train.data.2
train.data.2 <- train.data.2[, !(names(train.data.2) %in% low.var.cols)]
test.data.2 <- test.data.2[, !(names(test.data.2) %in% low.var.cols)]

# check if columns are in identical order
# identical(names(train.data.2), names(test.data.2))    --> true

# -------------------------------------------------------------------------------

# remove temp variables
rm(scaled_data, low.var.cols, nzv)
```


### PCA test for variable importance, only on train.data.2 -> Zian
```{r}
# reason: all vars are numeric, either dummy or continuous, and is standardized 
# for building Linear/Logistic/NN/KNN models

# obtain new numeric features (after all the processes above)
numeric.data <- train.data.2[, sapply(train.data.2, is.numeric)]

# get pca result
pca_result <- prcomp(numeric.data, center = TRUE, scale. = FALSE)
# summary(pca_result)

# -------------------------------------------------------------------------------

plot(pca_result, type = "l", main = "Scree Plot: Variance Explained by Each Principal Component")
# first principal component (PC1) explains a significantly larger portion of the variance
```

```{r}
# check variable loading of PC 1,2,3
# they explain most of the variance before the scree plot flattens.
loadings <- round(pca_result$rotation[, 1:3], 3)

# get all vars with loadings < 0.01 (low contribution)
low.contrib.vars <- rownames(loadings)[apply(abs(loadings) < 0.01, 1, all)]

cat("Low-contribution variables (loading < 0.01 across PC1–PC3):\n\n")
print(low.contrib.vars)

# remove vars with low contribution (loading near 0) 
# to reduce dimensionality without significant information loss
train.data.2 <- train.data.2[, !(names(train.data.2) %in% low.contrib.vars)]
test.data.2  <- test.data.2[, !(names(test.data.2) %in% low.contrib.vars)]

# -------------------------------------------------------------------------------

# check if columns are in identical order
identical(names(train.data.2), names(test.data.2))
dim(train.data.2)
dim(test.data.2)

# -------------------------------------------------------------------------------
# new pca result
pca_result <- prcomp(train.data.2[, sapply(train.data.2, is.numeric)],
                     center = TRUE, 
                     scale. = FALSE)
```


```{r}
# plot top 10 variables (by |PC1 loading|) in PC1–PC2 space
top_vars <- names(sort(abs(pca_result$rotation[, 1]), decreasing = TRUE)[1:10])
df <- as.data.frame(pca_result$rotation[top_vars, 1:2])
df$var <- rownames(df)

ggplot(df, aes(x = PC1, y = PC2, label = var)) +
  geom_segment(aes(xend = 0, yend = 0), arrow = arrow(length = unit(0.2, "cm"))) +
  geom_text_repel() +
  labs(title = "Top 10 PCA Variables", x = "PC1", y = "PC2") +
  theme_minimal()


# remove temp variables
rm(top_vars, df, low.contrib.vars, numeric.data, loadings)
```



###
Optional: PCA datasets for modeling(if implementing)
```{r}
# -> remove all categorical variables
# -> scaling
# train.data.3 <- train.data[, sapply(train.data, is.numeric)]
# train.data.3 <- scale(train.data.3)
```


*** remember to optimize model parameters***

### model 1: multiple linear model -> Thomas
```{r}
### while testing, do not only run this code chunk, 
###clear the environment & run from the beginning

# Convert income column to **numeric**
train.data.2$income <- as.numeric(ifelse(train.data.2$income == ">50K",1,0))
test.data.2$income <- as.numeric(ifelse(test.data.2$income == ">50K",1,0))

# -------------------------------------------------------------------------------

#fit mlr
mlr_model <- lm(income ~ ., data = train.data.2)
#prediction
pred_mlr <- predict(mlr_model, test.data.2)

# find y and y_hat
y <- test.data.2$income
yhat <- pred_mlr

# -------------------------------------------------------------------------------
# Predict class
yhat_binary <- ifelse(pred_mlr > 0.5, 1, 0)

# MSE
mse_mlr <- mean((y - yhat)^2)
print(paste("MLR MSE:", mse_mlr))

# Accuracy
accuracy_mlr <- mean(y == yhat_binary)
print(paste("MLR Accuracy:", accuracy_mlr))



# remove temp variables
rm(y, yhat, yhat_binary)
```


### model 2: logistic model -> Zian
data scaling

### model 3: NN model -> Tasfia
data scaling

### model 4: CART model -> Nicole
do not scale

### model 5: random forest model -> Matthew
do not scale

### model 6: extra models, PCA, KNN... -> decide latter

### explore XgBoost classification --> Thomas





```{r}
# check for data imbalance
table(train.data$income)
prop.table(table(train.data$income))
# somewhat imbalanced
```

### ***if model predicts income>50K poorly, try handle imbalance***





















